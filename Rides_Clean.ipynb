{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c20b07a",
   "metadata": {},
   "source": [
    "This script purpose is just to merge and clean trips2022.csv, trips2023.csv and trips2024.csv \n",
    "It is separated from the main file for optimization of resources and kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ab1f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b315e6",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177fec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Merging raw data from 2022, 2023, and 2024...\n",
      "üîÑ Processing 2022...\n",
      "‚úÖ 2022 loaded successfully!\n",
      "üîÑ Processing 2023...\n",
      "‚úÖ 2023 loaded successfully!\n",
      "üîÑ Processing 2024...\n",
      "‚úÖ 2024 loaded successfully!\n",
      "‚úÖ Merged dataset saved at: /home/chona/code/ignaciogomenuka/ChallengeDecentraland/data/Rides/trips_2022_2024_raw.csv\n",
      "‚úÖ Final dataset size: 8480620 rows, 21 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = \"/home/chona/code/ignaciogomenuka/ChallengeDecentraland/data/Rides/\"\n",
    "\n",
    "\n",
    "years = [2022, 2023, 2024]\n",
    "\n",
    "chunk_size = 1_000_000\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "print(\"üì• Merging raw data from 2022, 2023, and 2024...\")\n",
    "\n",
    "# Load each year in chunks to optimize Kernel\n",
    "for year in years:\n",
    "    file_path = f\"{base_path}trips_{year}.csv\"\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"üîÑ Processing {year}...\")\n",
    "\n",
    "        for chunk in pd.read_csv(file_path, low_memory=True, dtype=str, chunksize=chunk_size):\n",
    "            chunk[\"year\"] = year  \n",
    "            dataframes.append(chunk)\n",
    "\n",
    "        print(f\"‚úÖ {year} loaded successfully!\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipping {year}: File not found!\")\n",
    "\n",
    "rides_df_raw = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "merged_file_path = f\"{base_path}trips_2022_2024_raw.csv\"\n",
    "rides_df_raw.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Merged dataset saved at: {merged_file_path}\")\n",
    "print(f\"‚úÖ Final dataset size: {len(rides_df_raw)} rows, {len(rides_df_raw.columns)} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6074d4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Missing Values Per Column:\n",
      "                            Missing Values  Percentage (%)\n",
      "G√©nero                             5574121       65.727753\n",
      "X                                  5557815       65.535480\n",
      "g√©nero                             2944951       34.725657\n",
      "Unnamed: 0                         2935484       34.614026\n",
      "nombre_estacion_destino                  2        0.000024\n",
      "direccion_estacion_destino               2        0.000024\n",
      "lat_estacion_destino                     2        0.000024\n",
      "id_estacion_destino                      2        0.000024\n",
      "long_estacion_destino                    2        0.000024\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "null_counts = rides_df_raw.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "null_percentage = (null_counts / len(rides_df_raw)) * 100\n",
    "\n",
    "missing_data = pd.DataFrame({\n",
    "    \"Missing Values\": null_counts,\n",
    "    \"Percentage (%)\": null_percentage\n",
    "})\n",
    "\n",
    "print(\"Missing Values Per Column:\")\n",
    "print(missing_data[missing_data[\"Missing Values\"] > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a08f1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   g√©nero g√©nero\n",
      "0  FEMALE    NaN\n",
      "1    MALE    NaN\n",
      "2  FEMALE    NaN\n",
      "3  FEMALE    NaN\n",
      "4   OTHER    NaN\n",
      "5   OTHER    NaN\n",
      "6  FEMALE    NaN\n",
      "7    MALE    NaN\n",
      "8  FEMALE    NaN\n",
      "9    MALE    NaN\n",
      "'g√©nero' column unified successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "rides_df_raw.columns = rides_df_raw.columns.str.lower()\n",
    "\n",
    "if \"g√©nero\" in rides_df_raw.columns and \"g√©nero\" in rides_df_raw.columns:\n",
    "    rides_df_raw[\"g√©nero\"] = rides_df_raw[\"g√©nero\"].fillna(rides_df_raw[\"g√©nero\"])   \n",
    "\n",
    "print(rides_df_raw[\"g√©nero\"].head(10))\n",
    "print(f\"'g√©nero' column unified successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81e08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Columns 'X' and 'Unnamed: 0' have been dropped.\n",
      " Remaining columns: Index(['id_recorrido', 'duracion_recorrido', 'fecha_origen_recorrido',\n",
      "       'id_estacion_origen', 'nombre_estacion_origen',\n",
      "       'direccion_estacion_origen', 'long_estacion_origen',\n",
      "       'lat_estacion_origen', 'fecha_destino_recorrido', 'id_estacion_destino',\n",
      "       'nombre_estacion_destino', 'direccion_estacion_destino',\n",
      "       'long_estacion_destino', 'lat_estacion_destino', 'id_usuario',\n",
      "       'modelo_bicicleta', 'g√©nero', 'year', 'g√©nero'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rides_df_raw.drop(columns=[\"x\", \"unnamed: 0\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(f\" Columns 'X' and 'Unnamed: 0' have been dropped.\")\n",
    "print(f\" Remaining columns: {rides_df_raw.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad392f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset saved successfully at: /home/chona/code/ignaciogomenuka/ChallengeDecentraland/data/Rides/trips_2022_2024_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "cleaned_file_path = \"/home/chona/code/ignaciogomenuka/ChallengeDecentraland/data/Rides/trips_2022_2024_cleaned.csv\"\n",
    "\n",
    "rides_df_raw.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Cleaned dataset saved successfully at: {cleaned_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
